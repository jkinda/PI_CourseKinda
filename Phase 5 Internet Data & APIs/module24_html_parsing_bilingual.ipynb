{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92eb0657",
   "metadata": {},
   "source": [
    "# Module 24: HTML Parsing with BeautifulSoup\n",
    "## Module 24 : Parse HTML avec BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a098e89",
   "metadata": {},
   "source": [
    "## 1. Why This Matters / 1. Pourquoi c'est important\n",
    "- **English:** BeautifulSoup makes it easy to extract data from HTML, turning web pages into usable data.\n",
    "- **Français :** BeautifulSoup facilite l'extraction de données depuis le HTML, transformant les pages web en données exploitables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d70bb",
   "metadata": {},
   "source": [
    "## 2. Spaced & Interleaved Review / 2. Révision espacée et mélangée\n",
    "- **Flash-back:** How do you fetch web data with requests? / Comment récupère-t-on des données web avec requests ?\n",
    "- **Interleaving:** How could you combine loop and parsing to process multiple elements? / Comment combiner boucle et parsing pour traiter plusieurs éléments ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6d6ba",
   "metadata": {},
   "source": [
    "## 3. Quick Quiz / 3. Quiz rapide\n",
    "1. True or False: `BeautifulSoup(html, 'lxml')` parses with lxml parser. / Vrai ou Faux : `BeautifulSoup(html, 'lxml')` utilise le parser lxml.\n",
    "2. Which method finds all matching tags? / Quelle méthode trouve toutes les balises correspondantes ?\n",
    "3. How do you get the text inside a tag? / Comment obtenir le texte à l'intérieur d'une balise ?\n",
    "4. What attribute holds the href of an <a> tag? / Quel attribut contient le href d'une balise <a> ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc621d4",
   "metadata": {},
   "source": [
    "## 4. Learning Objectives / 4. Objectifs d'apprentissage\n",
    "By the end, you can: / À la fin, vous pourrez :\n",
    "- Parse HTML content with BeautifulSoup. / Parser du HTML avec BeautifulSoup.\n",
    "- Use the lxml parser for speed. / Utiliser le parser lxml pour la vitesse.\n",
    "- Find tags by name, class, or CSS selector. / Trouver des balises par nom, classe ou sélecteur CSS.\n",
    "- Extract text and attribute values. / Extraire du texte et des attributs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b5616",
   "metadata": {},
   "source": [
    "## 5. Core Content / 5. Contenu principal\n",
    "- **Import and parse / import et parse :**\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://example.com')\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "```  \n",
    "- **Finding tags / trouver des balises :**\n",
    "```python\n",
    "title = soup.title          # first <title>\n",
    "links = soup.find_all('a')  # all links\n",
    "```  \n",
    "- **Attributes / attributs :**\n",
    "```python\n",
    "for a in links:\n",
    "    print(a.get('href'))\n",
    "```  \n",
    "- **CSS selectors / sélecteurs CSS :**\n",
    "```python\n",
    "items = soup.select('.item-class > a')\n",
    "```  \n",
    "- **Extracting text / extraire le texte :**\n",
    "```python\n",
    "for p in soup.find_all('p'):\n",
    "    print(p.text)\n",
    "```  \n",
    "**Example (htmlparsing_finished.py) / Exemple :**\n",
    "```python\n",
    "# htmlparsing_finished.py\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://news.ycombinator.com/'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "links = soup.select('.titleline > a')\n",
    "for link in links:\n",
    "    print(link.text, '-', link['href'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b9ad7",
   "metadata": {},
   "source": [
    "## 6. Starter Code (Incomplete) / 6. Code de démarrage (incomplet)\n",
    "Complete the TODOs to parse HTML and extract data. / Complétez les TODO pour parser le HTML et extraire des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d61a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_parsing_starter.py\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://example.com'\n",
    "# TODO: fetch the page with requests\n",
    "r = None\n",
    "\n",
    "# TODO: create BeautifulSoup object with 'lxml' parser\n",
    "soup = None\n",
    "\n",
    "# TODO: find all <h2> tags and print their text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e606551c",
   "metadata": {},
   "source": [
    "## 7. Hands-On Project: Simple Scraper / 7. Projet pratique : Scraper simple\n",
    "- **Description:** Write a script that:\n",
    "  1. Asks user for a URL.\n",
    "  2. Fetches the page and parses it.\n",
    "  3. Extracts all headlines (<h1>, <h2>, <h3>) and prints them.\n",
    "- **Rubric / Barème:**\n",
    "  - Correct fetch and parse: 30% / Récupération et parse corrects : 30%\n",
    "  - Extraction of headings: 40% / Extraction des titres : 40%\n",
    "  - Handles missing tags gracefully: 20% / Gère les balises manquantes : 20%\n",
    "  - Code clarity & comments: 10% / Clarté du code et commentaires : 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c5a7f",
   "metadata": {},
   "source": [
    "## 8. Stretch Tasks / 8. Tâches supplémentaires\n",
    "- Allow scraping multiple pages in a loop. / Autoriser le scraping de plusieurs pages en boucle.\n",
    "- Save the results to CSV or JSON. / Enregistrer les résultats en CSV ou JSON.\n",
    "- Respect robots.txt before scraping. / Respecter le robots.txt avant le scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0784fb1",
   "metadata": {},
   "source": [
    "## 9. Reflection / 9. Réflexion\n",
    "- **Summary:** What new techniques did you learn for parsing HTML? / Quelles nouvelles techniques avez-vous apprises pour parser du HTML ?\n",
    "- **Muddiest point:** Any confusion with selectors? / Des doutes sur les sélecteurs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98bb87",
   "metadata": {},
   "source": [
    "## 10. Resources / 10. Ressources\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- https://lxml.de/\n",
    "- https://realpython.com/beautiful-soup-web-scraper-python/"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
